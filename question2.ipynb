{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP Arjun columns: Index([0, 1, 2, 3, 4, 5, 6, 7], dtype='int64')\n",
      "NLP Venkat columns: Index([0, 1, 2, 3, 4, 5, 6, 7], dtype='int64')\n",
      "CV Arjun columns: Index(['annotation_id', 'annotator', 'created_at', 'id', 'image', 'label',\n",
      "       'lead_time', 'updated_at'],\n",
      "      dtype='object')\n",
      "CV Venkat columns: Index(['annotation_id', 'annotator', 'created_at', 'id', 'image', 'label',\n",
      "       'lead_time', 'updated_at'],\n",
      "      dtype='object')\n",
      "CV 3rd member columns: Index(['annotation_id', 'annotator', 'created_at', 'id', 'image', 'label',\n",
      "       'lead_time', 'updated_at'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "nlp_annotator1 = pd.read_csv('arjunnlp.csv', header=None)\n",
    "nlp_annotator2 = pd.read_csv('venkatnlp.csv',header=None)\n",
    "\n",
    "cv_annotator1 = pd.read_csv('CV-annotations-Arjun.csv')\n",
    "cv_annotator2 = pd.read_csv('CV-annotations-Venkat.csv')\n",
    "cv_annotator3 = pd.read_csv('CV-annotations-3rd-member.csv')\n",
    "print(\"NLP Arjun columns:\", nlp_annotator1.columns)\n",
    "print(\"NLP Venkat columns:\", nlp_annotator2.columns)\n",
    "print(\"CV Arjun columns:\", cv_annotator1.columns)\n",
    "print(\"CV Venkat columns:\", cv_annotator2.columns)\n",
    "print(\"CV 3rd member columns:\", cv_annotator3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cohen_kappa_for_nlp(annotator1, annotator2):\n",
    " \n",
    "    \n",
    "    kappa = cohen_kappa_score(annotator1, annotator2)\n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa for NLP Task: -2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "nlp_kappa = cohen_kappa_for_nlp(nlp_annotator1[0], nlp_annotator2[1])\n",
    "print(f\"Cohen's Kappa for NLP Task: {nlp_kappa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [387, 378]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m labels2 \u001b[38;5;241m=\u001b[39m [label \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparsed_labels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m sublist]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate Cohen's Kappa score\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m kappa \u001b[38;5;241m=\u001b[39m \u001b[43mcohen_kappa_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCohen\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Kappa Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkappa\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Venkat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Venkat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:713\u001b[0m, in \u001b[0;36mcohen_kappa_score\u001b[1;34m(y1, y2, labels, weights, sample_weight)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    640\u001b[0m     {\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my1\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    648\u001b[0m )\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcohen_kappa_score\u001b[39m(y1, y2, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    650\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute Cohen's kappa: a statistic that measures inter-annotator agreement.\u001b[39;00m\n\u001b[0;32m    651\u001b[0m \n\u001b[0;32m    652\u001b[0m \u001b[38;5;124;03m    This function computes Cohen's kappa [1]_, a score that expresses the level\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;124;03m    0.6875\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 713\u001b[0m     confusion \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    714\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m confusion\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    715\u001b[0m     sum0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(confusion, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Venkat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Venkat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:342\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    248\u001b[0m     {\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    259\u001b[0m ):\n\u001b[0;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\Venkat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Venkat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [387, 378]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Load CSV files\n",
    "df1 = pd.read_csv('NLP-annotations-Arjun.csv')\n",
    "df2 = pd.read_csv('NLP-annotations-Venkat.csv')\n",
    "df2.rename(columns={'label': 'pos'}, inplace=True)\n",
    "\n",
    "# Ensure data alignment\n",
    "df1 = df1.sort_values(by='annotation_id').reset_index(drop=True)\n",
    "df2 = df2.sort_values(by='annotation_id').reset_index(drop=True)\n",
    "\n",
    "# Extract and flatten labels\n",
    "def extract_labels(label_str):\n",
    "    annotations = json.loads(label_str)\n",
    "    return [ann['labels'][0] for ann in annotations]\n",
    "\n",
    "df1['parsed_labels'] = df1['pos'].apply(extract_labels)\n",
    "df2['parsed_labels'] = df2['pos'].apply(extract_labels)\n",
    "\n",
    "# Flatten lists to a common format\n",
    "labels1 = [label for sublist in df1['parsed_labels'] for label in sublist]\n",
    "labels2 = [label for sublist in df2['parsed_labels'] for label in sublist]\n",
    "\n",
    "# Calculate Cohen's Kappa score\n",
    "kappa = cohen_kappa_score(labels1, labels2)\n",
    "print(f\"Cohen's Kappa Score: {kappa:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['annotation_id', 'annotator', 'created_at', 'id', 'lead_time', 'pos',\n",
      "       'text', 'updated_at'],\n",
      "      dtype='object')\n",
      "Index(['annotation_id', 'annotator', 'created_at', 'id', 'label', 'lead_time',\n",
      "       'text', 'updated_at'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df1.columns)\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>pos</th>\n",
       "      <th>text</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T12:49:02.475072Z</td>\n",
       "      <td>50</td>\n",
       "      <td>471.716</td>\n",
       "      <td>[{\"start\":0,\"end\":8,\"text\":\"Raymond \",\"labels\"...</td>\n",
       "      <td>Raymond MD Divorce: Raymond के MD गौतम सिंघानि...</td>\n",
       "      <td>2025-01-24T12:49:02.475072Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T12:56:29.850990Z</td>\n",
       "      <td>51</td>\n",
       "      <td>353.749</td>\n",
       "      <td>[{\"start\":0,\"end\":6,\"text\":\"Delhi \",\"labels\":[...</td>\n",
       "      <td>Delhi Rain: SC बोला- हमें नतीजे चाहिए, केजरीवा...</td>\n",
       "      <td>2025-01-24T12:56:29.850990Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T13:00:42.413094Z</td>\n",
       "      <td>52</td>\n",
       "      <td>236.918</td>\n",
       "      <td>[{\"start\":0,\"end\":3,\"text\":\"PM \",\"labels\":[\"PR...</td>\n",
       "      <td>PM कोई भी होता, G20 तो होना ही था... Modi का इ...</td>\n",
       "      <td>2025-01-24T13:00:42.413094Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotation_id  annotator                   created_at  id  lead_time  \\\n",
       "0             41          1  2025-01-24T12:49:02.475072Z  50    471.716   \n",
       "1             61          1  2025-01-24T12:56:29.850990Z  51    353.749   \n",
       "2             62          1  2025-01-24T13:00:42.413094Z  52    236.918   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  [{\"start\":0,\"end\":8,\"text\":\"Raymond \",\"labels\"...   \n",
       "1  [{\"start\":0,\"end\":6,\"text\":\"Delhi \",\"labels\":[...   \n",
       "2  [{\"start\":0,\"end\":3,\"text\":\"PM \",\"labels\":[\"PR...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Raymond MD Divorce: Raymond के MD गौतम सिंघानि...   \n",
       "1  Delhi Rain: SC बोला- हमें नतीजे चाहिए, केजरीवा...   \n",
       "2  PM कोई भी होता, G20 तो होना ही था... Modi का इ...   \n",
       "\n",
       "                    updated_at  \n",
       "0  2025-01-24T12:49:02.475072Z  \n",
       "1  2025-01-24T12:56:29.850990Z  \n",
       "2  2025-01-24T13:00:42.413094Z  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>text</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T10:49:13.766051Z</td>\n",
       "      <td>14538</td>\n",
       "      <td>[{\"start\":0,\"end\":8,\"text\":\"राजस्थान\",\"labels\"...</td>\n",
       "      <td>395.756</td>\n",
       "      <td>राजस्थान के CM बनने के सवाल पर क्या बोले केंद्...</td>\n",
       "      <td>2025-01-24T10:49:13.766051Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T10:55:00.198146Z</td>\n",
       "      <td>14539</td>\n",
       "      <td>[{\"start\":0,\"end\":5,\"text\":\"World\",\"labels\":[\"...</td>\n",
       "      <td>301.777</td>\n",
       "      <td>World Cup Final 2023: क्या रोहित-विराट अब वर्ल...</td>\n",
       "      <td>2025-01-24T10:55:00.198146Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T10:57:42.074330Z</td>\n",
       "      <td>14540</td>\n",
       "      <td>[{\"start\":0,\"end\":11,\"text\":\"Uttarkashi \",\"lab...</td>\n",
       "      <td>150.674</td>\n",
       "      <td>Uttarkashi Tunnel Rescue: उत्तरकाशी टनल में फं...</td>\n",
       "      <td>2025-01-24T10:57:42.074330Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotation_id  annotator                   created_at     id  \\\n",
       "0             22          1  2025-01-24T10:49:13.766051Z  14538   \n",
       "1             23          1  2025-01-24T10:55:00.198146Z  14539   \n",
       "2             24          1  2025-01-24T10:57:42.074330Z  14540   \n",
       "\n",
       "                                               label  lead_time  \\\n",
       "0  [{\"start\":0,\"end\":8,\"text\":\"राजस्थान\",\"labels\"...    395.756   \n",
       "1  [{\"start\":0,\"end\":5,\"text\":\"World\",\"labels\":[\"...    301.777   \n",
       "2  [{\"start\":0,\"end\":11,\"text\":\"Uttarkashi \",\"lab...    150.674   \n",
       "\n",
       "                                                text  \\\n",
       "0  राजस्थान के CM बनने के सवाल पर क्या बोले केंद्...   \n",
       "1  World Cup Final 2023: क्या रोहित-विराट अब वर्ल...   \n",
       "2  Uttarkashi Tunnel Rescue: उत्तरकाशी टनल में फं...   \n",
       "\n",
       "                    updated_at  \n",
       "0  2025-01-24T10:49:13.766051Z  \n",
       "1  2025-01-24T10:55:00.198146Z  \n",
       "2  2025-01-24T10:57:42.074330Z  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.rename(columns={'label': 'pos'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>pos</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>text</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T10:49:13.766051Z</td>\n",
       "      <td>14538</td>\n",
       "      <td>[{\"start\":0,\"end\":8,\"text\":\"राजस्थान\",\"labels\"...</td>\n",
       "      <td>395.756</td>\n",
       "      <td>राजस्थान के CM बनने के सवाल पर क्या बोले केंद्...</td>\n",
       "      <td>2025-01-24T10:49:13.766051Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T10:55:00.198146Z</td>\n",
       "      <td>14539</td>\n",
       "      <td>[{\"start\":0,\"end\":5,\"text\":\"World\",\"labels\":[\"...</td>\n",
       "      <td>301.777</td>\n",
       "      <td>World Cup Final 2023: क्या रोहित-विराट अब वर्ल...</td>\n",
       "      <td>2025-01-24T10:55:00.198146Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T10:57:42.074330Z</td>\n",
       "      <td>14540</td>\n",
       "      <td>[{\"start\":0,\"end\":11,\"text\":\"Uttarkashi \",\"lab...</td>\n",
       "      <td>150.674</td>\n",
       "      <td>Uttarkashi Tunnel Rescue: उत्तरकाशी टनल में फं...</td>\n",
       "      <td>2025-01-24T10:57:42.074330Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotation_id  annotator                   created_at     id  \\\n",
       "0             22          1  2025-01-24T10:49:13.766051Z  14538   \n",
       "1             23          1  2025-01-24T10:55:00.198146Z  14539   \n",
       "2             24          1  2025-01-24T10:57:42.074330Z  14540   \n",
       "\n",
       "                                                 pos  lead_time  \\\n",
       "0  [{\"start\":0,\"end\":8,\"text\":\"राजस्थान\",\"labels\"...    395.756   \n",
       "1  [{\"start\":0,\"end\":5,\"text\":\"World\",\"labels\":[\"...    301.777   \n",
       "2  [{\"start\":0,\"end\":11,\"text\":\"Uttarkashi \",\"lab...    150.674   \n",
       "\n",
       "                                                text  \\\n",
       "0  राजस्थान के CM बनने के सवाल पर क्या बोले केंद्...   \n",
       "1  World Cup Final 2023: क्या रोहित-विराट अब वर्ल...   \n",
       "2  Uttarkashi Tunnel Rescue: उत्तरकाशी टनल में फं...   \n",
       "\n",
       "                    updated_at  \n",
       "0  2025-01-24T10:49:13.766051Z  \n",
       "1  2025-01-24T10:55:00.198146Z  \n",
       "2  2025-01-24T10:57:42.074330Z  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 9), (20, 9))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   annotation_id                                                pos\n",
      "0             41  [{\"start\":0,\"end\":8,\"text\":\"Raymond \",\"labels\"...\n",
      "1             61  [{\"start\":0,\"end\":6,\"text\":\"Delhi \",\"labels\":[...\n",
      "2             62  [{\"start\":0,\"end\":3,\"text\":\"PM \",\"labels\":[\"PR...\n",
      "3             63  [{\"start\":0,\"end\":9,\"text\":\"Priyanka \",\"labels...\n",
      "4             64  [{\"start\":0,\"end\":9,\"text\":\"Priyanka \",\"labels...\n",
      "   annotation_id                                                pos\n",
      "0             22  [{\"start\":0,\"end\":8,\"text\":\"राजस्थान\",\"labels\"...\n",
      "1             23  [{\"start\":0,\"end\":5,\"text\":\"World\",\"labels\":[\"...\n",
      "2             24  [{\"start\":0,\"end\":11,\"text\":\"Uttarkashi \",\"lab...\n",
      "3             25  [{\"start\":0,\"end\":6,\"text\":\"World \",\"labels\":[...\n",
      "4             26  [{\"start\":0,\"end\":6,\"text\":\"World \",\"labels\":[...\n"
     ]
    }
   ],
   "source": [
    "print(df1[['annotation_id', 'pos']].head())\n",
    "print(df2[['annotation_id', 'pos']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch in label counts: 14 vs 19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Load CSV files\n",
    "df1 = pd.read_csv('NLP-annotations-Arjun.csv')\n",
    "df2 = pd.read_csv('NLP-annotations-Venkat.csv')\n",
    "\n",
    "# Rename 'label' column to 'pos' in df2 to match df1\n",
    "df2.rename(columns={'label': 'pos'}, inplace=True)\n",
    "\n",
    "# Ensure data alignment based on annotation_id\n",
    "df1 = df1.sort_values(by='annotation_id').reset_index(drop=True)\n",
    "df2 = df2.sort_values(by='annotation_id').reset_index(drop=True)\n",
    "\n",
    "# Merge both dataframes to keep only common annotation IDs\n",
    "merged_df = pd.merge(df1[['annotation_id', 'pos']], df2[['annotation_id', 'pos']], on='annotation_id', how='inner')\n",
    "\n",
    "# Function to safely extract labels\n",
    "def extract_labels(label_str):\n",
    "    try:\n",
    "        annotations = json.loads(label_str)\n",
    "        return [ann['labels'][0] for ann in annotations]\n",
    "    except (json.JSONDecodeError, KeyError, TypeError):\n",
    "        return []  # Return empty list if parsing fails\n",
    "\n",
    "# Apply the label extraction function\n",
    "merged_df['parsed_labels_1'] = merged_df['pos_x'].apply(extract_labels)\n",
    "merged_df['parsed_labels_2'] = merged_df['pos_y'].apply(extract_labels)\n",
    "\n",
    "# Flatten the lists of parsed labels\n",
    "labels1 = [label for sublist in merged_df['parsed_labels_1'] for label in sublist]\n",
    "labels2 = [label for sublist in merged_df['parsed_labels_2'] for label in sublist]\n",
    "\n",
    "# Ensure both lists have the same length before calculating Cohen's Kappa\n",
    "if len(labels1) == len(labels2):\n",
    "    kappa = cohen_kappa_score(labels1, labels2)\n",
    "    print(f\"Cohen's Kappa Score: {kappa:.2f}\")\n",
    "else:\n",
    "    print(f\"Mismatch in label counts: {len(labels1)} vs {len(labels2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient samples for reliable calculation.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_annotations(file1, file2):\n",
    "    \"\"\"\n",
    "    Load and preprocess annotation files for inter-annotator reliability analysis.\n",
    "    \"\"\"\n",
    "    # Load CSV files\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    # Ensure correct column names\n",
    "    df1 = df1.rename(columns={'label': 'pos'} if 'label' in df1.columns else {})\n",
    "    df2 = df2.rename(columns={'label': 'pos'} if 'label' in df2.columns else {})\n",
    "\n",
    "    # Merge on annotation_id\n",
    "    merged_df = pd.merge(df1[['annotation_id', 'pos']], \n",
    "                         df2[['annotation_id', 'pos']], \n",
    "                         on='annotation_id', \n",
    "                         how='inner', \n",
    "                         suffixes=('_1', '_2'))\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "def extract_labels(label_str):\n",
    "    \"\"\"\n",
    "    Extract primary labels from JSON-formatted annotation string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        annotations = json.loads(label_str)\n",
    "        return [ann['labels'][0] for ann in annotations]\n",
    "    except (json.JSONDecodeError, KeyError, TypeError):\n",
    "        return []\n",
    "\n",
    "def calculate_inter_annotator_reliability(merged_df):\n",
    "    \"\"\"\n",
    "    Calculate inter-annotator reliability metrics.\n",
    "    \"\"\"\n",
    "    # Extract labels for each annotator\n",
    "    merged_df['parsed_labels_1'] = merged_df['pos_1'].apply(extract_labels)\n",
    "    merged_df['parsed_labels_2'] = merged_df['pos_2'].apply(extract_labels)\n",
    "\n",
    "    # Prepare lists to store encoded labels\n",
    "    labels1_encoded = []\n",
    "    labels2_encoded = []\n",
    "\n",
    "    # Get unique labels\n",
    "    all_labels = set()\n",
    "    for labels in merged_df['parsed_labels_1'] + merged_df['parsed_labels_2']:\n",
    "        all_labels.update(labels)\n",
    "    \n",
    "    # Create label to index mapping\n",
    "    label_to_index = {label: idx for idx, label in enumerate(sorted(all_labels))}\n",
    "\n",
    "    # Encode labels\n",
    "    for idx, row in merged_df.iterrows():\n",
    "        # Ensure both annotators have labels for this instance\n",
    "        if row['parsed_labels_1'] and row['parsed_labels_2']:\n",
    "            # Take first label if multiple exist\n",
    "            label1 = row['parsed_labels_1'][0]\n",
    "            label2 = row['parsed_labels_2'][0]\n",
    "            \n",
    "            labels1_encoded.append(label_to_index[label1])\n",
    "            labels2_encoded.append(label_to_index[label2])\n",
    "\n",
    "    # Calculate reliability metrics\n",
    "    if len(labels1_encoded) > 1:\n",
    "        kappa = cohen_kappa_score(labels1_encoded, labels2_encoded)\n",
    "        conf_matrix = confusion_matrix(labels1_encoded, labels2_encoded)\n",
    "        \n",
    "        return {\n",
    "            'cohens_kappa': kappa,\n",
    "            'total_samples': len(labels1_encoded),\n",
    "            'label_mapping': label_to_index,\n",
    "            'confusion_matrix': conf_matrix\n",
    "        }\n",
    "    else:\n",
    "        print(\"Insufficient samples for reliable calculation.\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # Paths to annotation files\n",
    "    file1 = 'NLP-annotations-Arjun.csv'\n",
    "    file2 = 'NLP-annotations-Venkat.csv'\n",
    "    \n",
    "    # Load and merge annotations\n",
    "    merged_df = load_and_preprocess_annotations(file1, file2)\n",
    "    \n",
    "    # Calculate reliability metrics\n",
    "    reliability_results = calculate_inter_annotator_reliability(merged_df)\n",
    "    \n",
    "    # Print results\n",
    "    if reliability_results:\n",
    "        print(\"Inter-Annotator Reliability Analysis\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Cohen's Kappa Score: {reliability_results['cohens_kappa']:.4f}\")\n",
    "        print(f\"Total Samples Analyzed: {reliability_results['total_samples']}\")\n",
    "        \n",
    "        print(\"\\nLabel Mapping:\")\n",
    "        for label, index in reliability_results['label_mapping'].items():\n",
    "            print(f\"{label}: {index}\")\n",
    "        \n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(reliability_results['confusion_matrix'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa: nan\n",
      "Total Samples: 1\n",
      "Label Mapping: {'PROPN': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Venkat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Venkat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:730: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def calculate_kappa(file1, file2):\n",
    "    # Load files\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    # Ensure correct column names\n",
    "    df1 = df1.rename(columns={'label': 'pos'} if 'label' in df1.columns else {})\n",
    "    df2 = df2.rename(columns={'label': 'pos'} if 'label' in df2.columns else {})\n",
    "\n",
    "    # Merge on annotation_id\n",
    "    merged_df = pd.merge(df1[['annotation_id', 'pos']], \n",
    "                         df2[['annotation_id', 'pos']], \n",
    "                         on='annotation_id', \n",
    "                         how='inner')\n",
    "\n",
    "    def extract_first_labels(label_str):\n",
    "        try:\n",
    "            annotations = json.loads(label_str)\n",
    "            return [ann['labels'][0] for ann in annotations]\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "    # Extract labels\n",
    "    merged_df['labels1'] = merged_df['pos_x'].apply(extract_first_labels)\n",
    "    merged_df['labels2'] = merged_df['pos_y'].apply(extract_first_labels)\n",
    "\n",
    "    # Prepare label lists, filtering out empty entries\n",
    "    labels1 = [lst[0] for lst in merged_df['labels1'] if lst]\n",
    "    labels2 = [lst[0] for lst in merged_df['labels2'] if lst]\n",
    "\n",
    "    # Ensure same length and non-empty\n",
    "    min_len = min(len(labels1), len(labels2))\n",
    "    labels1 = labels1[:min_len]\n",
    "    labels2 = labels2[:min_len]\n",
    "\n",
    "    # Get unique labels for encoding\n",
    "    unique_labels = sorted(set(labels1 + labels2))\n",
    "    label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "    # Encode labels\n",
    "    encoded1 = [label_map[label] for label in labels1]\n",
    "    encoded2 = [label_map[label] for label in labels2]\n",
    "\n",
    "    # Calculate Kappa\n",
    "    kappa = cohen_kappa_score(encoded1, encoded2)\n",
    "    \n",
    "    return {\n",
    "        'kappa': kappa, \n",
    "        'label_mapping': label_map,\n",
    "        'total_samples': len(encoded1)\n",
    "    }\n",
    "\n",
    "# Usage\n",
    "result = calculate_kappa('NLP-annotations-Arjun.csv', 'NLP-annotations-Venkat.csv')\n",
    "print(f\"Cohen's Kappa: {result['kappa']:.4f}\")\n",
    "print(f\"Total Samples: {result['total_samples']}\")\n",
    "print(\"Label Mapping:\", result['label_mapping'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
